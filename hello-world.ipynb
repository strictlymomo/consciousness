{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial, we learn how to:\n",
        "- load text+metadata records from a dataset\n",
        "- inspect and preprocess raw texts\n",
        "- add a collection of documents processed by spaCy into a corpus\n",
        "- inspect aggregated corpus metadata\n",
        "- extract different kinds of structured data from one or many documents"
      ],
      "metadata": {
        "id": "O0kH5tKLJw0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textacy"
      ],
      "metadata": {
        "id": "1SVk-TM3BhVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb6b4a7-4ad7-4ae8-ce70-c1766c4ca7ca"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textacy\n",
            "  Downloading textacy-0.13.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: cachetools>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (5.5.0)\n",
            "Requirement already satisfied: catalogue~=2.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (2.0.10)\n",
            "Collecting cytoolz>=0.10.1 (from textacy)\n",
            "  Downloading cytoolz-0.12.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting floret~=0.10.0 (from textacy)\n",
            "  Downloading floret-0.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: jellyfish>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.1.0)\n",
            "Requirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.4.2)\n",
            "Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.10/dist-packages (from textacy) (3.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.26.4)\n",
            "Collecting pyphen>=0.10.0 (from textacy)\n",
            "  Downloading pyphen-0.16.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.3.2)\n",
            "Requirement already satisfied: spacy~=3.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (3.7.6)\n",
            "Requirement already satisfied: tqdm>=4.19.6 in /usr/local/lib/python3.10/dist-packages (from textacy) (4.66.5)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from cytoolz>=0.10.1->textacy) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->textacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->textacy) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->textacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->textacy) (2024.7.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->textacy) (3.5.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (2.4.8)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (0.12.5)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (3.4.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy~=3.0->textacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy~=3.0->textacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy~=3.0->textacy) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy~=3.0->textacy) (4.12.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy~=3.0->textacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy~=3.0->textacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy~=3.0->textacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy~=3.0->textacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy~=3.0->textacy) (13.8.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy~=3.0->textacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy~=3.0->textacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy~=3.0->textacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy~=3.0->textacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy~=3.0->textacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy~=3.0->textacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy~=3.0->textacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy~=3.0->textacy) (0.1.2)\n",
            "Downloading textacy-0.13.0-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cytoolz-0.12.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading floret-0.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.4/320.4 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyphen-0.16.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, floret, cytoolz, textacy\n",
            "Successfully installed cytoolz-0.12.3 floret-0.10.5 pyphen-0.16.0 textacy-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SUBxCULCBY_r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "117a0ac2-db69-47c1-dfc2-d5e0ff144e3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11.9M/11.9M [00:00<00:00, 41.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Explore how certain members of the U.S. Congress have spoken about 'workers'\n",
        "#   - dataset of thousands of speeches sourced from the Congressional Record.\n",
        "\n",
        "import textacy.datasets\n",
        "\n",
        "def load_dataset():\n",
        "  dataset = textacy.datasets.CapitolWords()\n",
        "  dataset.info\n",
        "  {'name': 'capitol_words',\n",
        "  'site_url': 'http://sunlightlabs.github.io/Capitol-Words/',\n",
        "  'description': 'Collection of ~11k speeches in the Congressional Record given by notable U.S. politicians between Jan 1996 and Jun 2016.'}\n",
        "  dataset.download()\n",
        "  return dataset\n",
        "\n",
        "dataset = load_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Each record contains full text of speech and basic metadata\n",
        "\n",
        "record = next(dataset.records(limit=1))\n",
        "record\n"
      ],
      "metadata": {
        "id": "7yd3rI-nBvhu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c14c2ed-4e84-4b84-9477-f66fe07b740e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Record(text='Mr. Speaker, 480,000 Federal employees are working without pay, a form of involuntary servitude; 280,000 Federal employees are not working, and they will be paid. Virtually all of these workers have mortgages to pay, children to feed, and financial obligations to meet.\\nMr. Speaker, what is happening to these workers is immoral, is wrong, and must be rectified immediately. Newt Gingrich and the Republican leadership must not continue to hold the House and the American people hostage while they push their disastrous 7-year balanced budget plan. The gentleman from Georgia, Mr. Gingrich, and the Republican leadership must join Senator Dole and the entire Senate and pass a continuing resolution now, now to reopen Government.\\nMr. Speaker, that is what the American people want, that is what they need, and that is what this body must do.', meta={'date': '1996-01-04', 'congress': 104, 'speaker_name': 'Bernie Sanders', 'speaker_party': 'I', 'title': 'JOIN THE SENATE AND PASS A CONTINUING RESOLUTION', 'chamber': 'House'})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Avoid a full read-through and extract only specific parts of interest\n",
        "\n",
        "from textacy import extract\n",
        "textacy.set_doc_extensions(\"extract\")  # just setting these now -- we'll use them later!\n",
        "\n",
        "# As a first step, inspect our keywords in context\n",
        "list(extract.keyword_in_context(record.text, \"work(ing|ers?)\", window_width=35))\n"
      ],
      "metadata": {
        "id": "IDS9s37yCBJp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "137e4f4e-5002-4592-e6c9-4b5242ed8f31"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ker, 480,000 Federal employees are ',\n",
              "  'working',\n",
              "  ' without pay, a form of involuntary'),\n",
              " (' 280,000 Federal employees are not ',\n",
              "  'working',\n",
              "  ', and they will be paid. Virtually '),\n",
              " ('ll be paid. Virtually all of these ',\n",
              "  'workers',\n",
              "  ' have mortgages to pay, children to'),\n",
              " ('peaker, what is happening to these ',\n",
              "  'workers',\n",
              "  ' is immoral, is wrong, and must be ')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the text to get rid of potential data quality issues and other distractions that may affect our analysis\n",
        "\n",
        "from textacy import preprocessing as preproc\n",
        "\n",
        "preprocessor = preproc.make_pipeline(\n",
        "    preproc.normalize.unicode,\n",
        "    preproc.normalize.quotation_marks,\n",
        "    preproc.normalize.whitespace,\n",
        ")\n",
        "preproc_text = preprocessor(record.text)\n",
        "preproc_text[:200]\n",
        "\n",
        "# changes are “destructive” — can’t reconstruct the original without keeping a copy around or re-loading it from disk\n"
      ],
      "metadata": {
        "id": "LuoBKF4cCO42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5487464e-1820-4276-9178-ed6a5320d2fe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mr. Speaker, 480,000 Federal employees are working without pay, a form of involuntary servitude; 280,000 Federal employees are not working, and they will be paid. Virtually all of these workers have m'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make a spaCy Doc by applying a language-specific model pipeline to the text\n",
        "\n",
        "doc = textacy.make_spacy_doc((preproc_text, record.meta), lang=\"en_core_web_sm\")\n",
        "doc._.preview\n",
        "doc._.meta\n"
      ],
      "metadata": {
        "id": "BmzZgvoXCoDg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3679997e-9871-4126-9b0c-56cf1328bf7f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'date': '1996-01-04',\n",
              " 'congress': 104,\n",
              " 'speaker_name': 'Bernie Sanders',\n",
              " 'speaker_party': 'I',\n",
              " 'title': 'JOIN THE SENATE AND PASS A CONTINUING RESOLUTION',\n",
              " 'chamber': 'House'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get a sense of how 'workers' are described using annotated part-of-speech tags\n",
        "\n",
        "# extract just the adjectives and determinants immediately preceding our keyword\n",
        "patterns = [\n",
        "    {\n",
        "        \"POS\": {\n",
        "            \"IN\": [\"ADJ\", \"DET\"]\n",
        "            },\n",
        "        \"OP\": \"+\"\n",
        "    },\n",
        "    {\n",
        "        \"ORTH\": {\n",
        "            \"REGEX\": \"workers?\"\n",
        "            }\n",
        "    }\n",
        "]\n",
        "token_matches = extract.token_matches(doc, patterns)\n",
        "list(token_matches)\n",
        "\n",
        "# examples aren’t very interesting. would like results aggregated over all speeches: skilled workers, American workers, young workers..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_anzq0GjC5_a",
        "outputId": "364285ff-200b-483e-c55f-467695b7c0eb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[these workers, these workers]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To accomplish this, load many records into a textacy.Corpus\n",
        "\n",
        "records = dataset.records(limit=500)\n",
        "preproc_records = ((preprocessor(text), meta) for text, meta in records)\n",
        "corpus = textacy.Corpus(\"en_core_web_sm\", data=preproc_records)\n",
        "print(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSZIpU4SDapN",
        "outputId": "3fa062bd-479b-4352-8130-5b8a04848031"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus(500 docs, 291289 tokens)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get a better sense of what’s in our corpus by leveraging the documents’ metadata\n",
        "import collections\n",
        "\n",
        "date = corpus.agg_metadata(\"date\", min), corpus.agg_metadata(\"date\", max)\n",
        "speaker_name = corpus.agg_metadata(\"speaker_name\", collections.Counter)\n",
        "\n",
        "print(date)\n",
        "print(speaker_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozI94BWNDpna",
        "outputId": "80214e6e-9563-41a0-c745-27b2b4f68ce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('1996-01-04', '1997-04-24')\n",
            "Counter({'Rick Santorum': 147, 'Joseph Biden': 140, 'John Kasich': 99, 'Bernie Sanders': 92, 'Lindsey Graham': 22})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract matches from each processed document\n",
        "\n",
        "import itertools\n",
        "\n",
        "matches = itertools.chain.from_iterable(extract.token_matches(doc, patterns) for doc in corpus)\n",
        "\n",
        "# lemmatize their texts for consistency\n",
        "# inspect the most common descriptions of workers\n",
        "collections.Counter(match.lemma_ for match in matches).most_common(20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bt_F6lcMGwPm",
        "outputId": "c01986bc-4770-4a94-ed5a-830002bf7ae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('american worker', 38),\n",
              " ('those worker', 5),\n",
              " ('the worker', 5),\n",
              " ('average american worker', 4),\n",
              " ('the average american worker', 4),\n",
              " ('more worker', 3),\n",
              " ('nonunion worker', 3),\n",
              " ('these worker', 2),\n",
              " ('federal worker', 2),\n",
              " ('that worker', 2),\n",
              " ('young worker', 2),\n",
              " ('skilled worker', 1),\n",
              " ('the more worker', 1),\n",
              " ('average worker', 1),\n",
              " ('young american worker', 1),\n",
              " ('most american worker', 1),\n",
              " ('any worker', 1),\n",
              " ('a worker', 1),\n",
              " ('social worker', 1),\n",
              " ('the social worker', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To better understand the context of these mentions, extract keyterms (the most important or “key” terms)\n",
        "\n",
        "corpus[0]._.extract_keyterms(\"textrank\", normalize=\"lemma\", window_size=10, edge_weighting=\"count\", topn=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bnCV2c0Hvuk",
        "outputId": "675fd96c-d2c1-4917-964f-4622c632ce67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('year balanced budget plan', 0.033721812470386026),\n",
              " ('Mr. Speaker', 0.032162715590532916),\n",
              " ('Mr. Gingrich', 0.031358819981176664),\n",
              " ('american people', 0.02612752273629427),\n",
              " ('republican leadership', 0.025418705021243045),\n",
              " ('federal employee', 0.021731159162187104),\n",
              " ('Newt Gingrich', 0.01988327361247088),\n",
              " ('pay', 0.018930131314143193),\n",
              " ('involuntary servitude', 0.015559235022115406),\n",
              " ('entire Senate', 0.015032623278646105)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, select the subset of speeches in which “worker(s)” were mentioned\n",
        "docs_mentioning_workers = corpus.get(lambda doc: any(doc._.extract_regex_matches(\"workers?\")))\n",
        "\n",
        "# extract the keyterms from each and aggregaate\n",
        "kt_weights = collections.Counter()\n",
        "\n",
        "for doc in docs_mentioning_workers:\n",
        "  keyterms = doc._.extract_keyterms(\n",
        "      \"textrank\", normalize=\"lemma\",\n",
        "      window_size=10,\n",
        "      edge_weighting=\"count\",\n",
        "      topn=10\n",
        "  )\n",
        "  kt_weights.update(dict(keyterms))\n",
        "\n",
        "# rank the results\n",
        "kt_weights.most_common(20)\n",
        "\n",
        "# we can see from the list that 'workers' are brought up in discussion of jobs, the minimum wage, and trust funds. Makes sense!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-iASaVvH_Ev",
        "outputId": "86bc0be8-e3f7-4af5-deb7-4dd0a0aaf81b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('minimum wage today', 0.15268345523692883),\n",
              " ('Mr. Speaker', 0.12629658074837496),\n",
              " ('real wage', 0.11170539679079608),\n",
              " ('minimum wage', 0.10559792485488079),\n",
              " ('wage job', 0.10102361828065554),\n",
              " ('american worker', 0.09808577723575501),\n",
              " ('family friendly company', 0.07527248179516885),\n",
              " ('american people', 0.07230595280822841),\n",
              " ('family work strategy', 0.07139211174164181),\n",
              " ('new job', 0.07009455277537283),\n",
              " ('tax dollar', 0.06415552977734736),\n",
              " ('violent crime trust fund', 0.0606067871587139),\n",
              " ('crime bill trust fund', 0.060534358199475835),\n",
              " ('crime law trust fund', 0.05916903052361145),\n",
              " ('time job', 0.05699067136562007),\n",
              " ('russian poultry market', 0.05179865219250223),\n",
              " ('temporary job', 0.051032675437375746),\n",
              " ('low wage job', 0.05086241618977966),\n",
              " ('health care reform bill', 0.05047788075809563),\n",
              " ('Kennedy health insurance reform bill', 0.05024956756215013)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}